\documentclass[a4paper,12pt,oneside]{report}

\newif\ifrelease % new boolean variable release. True = include some fancy content
\releasetrue % and set it

\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{epsfig}
\usepackage{graphicx}
\ifrelease
	\usepackage{pdfpages}
\fi
\usepackage[pagebackref=true]{hyperref} % tento balicek by mel byt na konci baliku!

\hypersetup{
	pdfauthor={Matej Laitl},
	pdftitle={Implementation environment for Bayesian filtering algorithms}
}

%% Nastavení zrcadla sazby
\usepackage{calc}
\setlength{\textheight}{9in}
\setlength{\textwidth}{6in}
\setlength\oddsidemargin{(\paperwidth-\textwidth)/2 - 1in}
\setlength\evensidemargin{(\paperwidth-\textwidth)/2 - 1in}
\setlength\topmargin{(\paperheight-\textheight-\headheight-\headsep-\footskip)/2 - 1in}

% TODO: je toto potreba?
%\parindent=0pt % odsazení 1. řádku odstavce
\parskip=7pt   % mezera mezi odstavci

\ifrelease
	\hypersetup{pdfborder={0 0 0}} % no borders around links
\else
	\hypersetup{colorlinks=true} % colour links instead of borders
\fi

\newcommand{\pdf}{probability density function }
\newcommand{\pdfs}{probability density functions }

\begin{document}

\ifrelease
	\input{startpages.tex} % include some fancy start pages
\fi


% obsah
\newpage
\tableofcontents


\chapter*{Introduction} \addcontentsline{toc}{chapter}{Introduction}

TODO motivatin for bayes filtration + a need for a convenient library (rapid prototyping vs. speed)

applications: robotics, navigation, + tracking of toxic plume after radiation accident.

Decision-making being a logical and natural ``next step'' - beyond the scope of this text.

[proposed citations:\cite{ThrBurFox:05,Gus:02,HofSmi:09,HofSmiPech:09,PechHofSmi:09}]


\chapter*{Notation} \addcontentsline{toc}{chapter}{Notation}

Throughout this text, following notation is used

\bigskip

\begin{tabular}{l p{0.8\textwidth}}
	\(\mathbb{N}\) & set of natural numbers \\
	\(\mathbb{R}\) & set of real numbers \\
	\(t\) & discrete time moment; \(t \in \mathbb{N}\) \\
	\(a_t\) & value of quantity \(a\) at time \(t\); \(a_t \in \mathbb{R}^n, n \in \mathbb{N}\) \\
		& unless noted otherwise, \(x_t\) denotes state vector at time \(t\) and \(y_t\) denotes
		  observation vector at time \(t\) \\
	\(a_{i:j}\) & sequence of quantities \((a_i, a_{i+1} \dots a_{j-1}, a_j)\) \\
\end{tabular}


\chapter{Basics of Recursive Bayesian Estimation}

In following sections the problem of recursive Bayesian estimation is stated and its anylitical
solution is derived. Later on, due to practical intractability of the solution in its general form,
a few methods that either simplify the problem or approximate the solution are shown.

\section{Problem Statement}

Assume a dynamic system described by a hidden real-valued \emph{state vector} \(x\) which evolves at
discrete time steps according to a known function \(f_t\) (in this text called \emph{process model})
as described by \eqref{eq:DynSysFt}.

\begin{equation} \label{eq:DynSysFt}
	x_t = f_t(x_{t-1}, v_{t-1})
\end{equation}

Variable \(v_t\) in \eqref{eq:DynSysFt} denotes random \emph{process noise}, which may come from various
sources and is often inevitable. Sequence of \(v_t\) is assumed to be identically independently
distributed random variable sequence.

The state of the system is hidden and can only be observed though a real-valued \emph{observation vector}
\(y\) that relates to the state \(x\) as in \eqref{eq:DynSysHt}, but adds further \emph{observation
noise} \(w\).

\begin{equation} \label{eq:DynSysHt}
	y_t = h_t(x_t, w_t)
\end{equation}

In \eqref{eq:DynSysHt} \(h_t\) is known function called \emph{observation model} in this text and \(w_t\) is
identically independently distributed random variable sequence that denotes observation noise.

The goal of recursive\footnote{by the word recursive we mean that it is not needed to keep track of
the whole batch of previous observations in practical methods, only appropriate quantities from time
moments \(t-1\) and \(t\) are needed to estimate \(x_t\). However, this does not apply to the
derivation of the solution, where the notation of whole batch of observations \(y_{1:t}\) is used.}
Bayesian estimation is to give an estimate of the state \(x_t\) given the
observations \(y_{1:t}\) provided the knowledge of the functions \(f_t\) and \(h_t\).
More formally, the goal is to find the \pdf \(p(x_t | y_{1:t})\).
Theoretical solution to this problem is known and is presented in next section.

\section{Theoretical solution}

At first, we observe that \pdf \(p(x_t|x_{t-1})\) can be derived from
\eqref{eq:DynSysFt} (given the distribution of \(v_k\)) and that \(p(y_t|x_t)\) can be derived from
\eqref{eq:DynSysHt} respectively. (given the distribution of \(w_k\))

Because recursive solution is requested, suppose that \(p(x_{t-1}|y_{1:t-1})\) and
\(p(x_0)\)\footnote{known as the initial \pdf of the state vector} are known in order to be
able to make the transition \(t-1 \; \rightarrow \; t\).

In the first stage called \emph{prediction}, \emph{a priori} \pdf
\(p(x_t | y_{1:t-1})\) is calculated without knowledge of \(y_t\). We begin the derivation by
performing the reverse of the marginalization over \(x_{k-1}\).

\begin{equation*}
	p(x_t | y_{1:t-1}) = \int_{-\infty}^{\infty} p(x_t, x_{t-1} | y_{1:t-1}) \; \mathrm{d} x_{t-1}
\end{equation*}

Using chain rule for \pdfs, the element of integration can be splitted.

\begin{equation*}
	p(x_t | y_{1:t-1}) = \int_{-\infty}^{\infty} p(x_t | x_{t-1}, y_{1:t-1}) p(x_{t-1} | y_{1:t-1}) \; \mathrm{d} x_{t-1}
\end{equation*}

But \(p(x_t | x_{t-1}, y_{1:t-1})\) equals \(p(x_t | x_{t-1})\) in accordance with the process model
\eqref{eq:DynSysFt} (TODO: Am I right?), leaving us with the result \eqref{eq:APrioriPdf}.

\begin{equation} \label{eq:APrioriPdf}
	p(x_t | y_{1:t-1}) = \int_{-\infty}^{\infty} p(x_t | x_{t-1}) p(x_{t-1} | y_{1:t-1}) \; \mathrm{d} x_{t-1}
\end{equation}

As we can see, a priori \pdf only depends on previously known functions and therefore can be
calculated.

We continue with the second stage called \emph{update}, where new observation \(y_t\) is taken into
account and \emph{a posteriori} \pdf \(p(x_t | y_{1:t})\) is calculated. Bayes' theorem can be used
to derive a posteriori \pdf \eqref{eq:APosterioriPdfRaw}.

\begin{equation} \label{eq:APosterioriPdfRaw}
	p(x_t | y_{1:t}) = \frac{p(y_t | x_t, y_{1:t-1}) p(x_t | y_{1:t-1})}{p(y_t | y_{1:t-1})}
\end{equation}

According to the observation model \eqref{eq:DynSysHt}, \(y_t\) only depends on \(x_t\) (so that
\(p(y_t | x_t, y_{1:t-1}) = p(y_t | x_t)\)) and aposteriori \pdf can be further simplified into
\eqref{eq:APosterioriPdf}. (TODO: Am I right?)

\begin{equation} \label{eq:APosterioriPdf}
	p(x_t | y_{1:t}) = \frac{p(y_t | x_t) p(x_t | y_{1:t-1})}{p(y_t | y_{1:t-1})}
\end{equation}

While both \pdfs in the numerator of \eqref{eq:APosterioriPdf} are already known, \(p(y_t|y_{1:t-1})\)
found in the denominator can be calculated using the formula \eqref{eq:NormConstant}, where
marginalization over \(x_t\) is preformed.

\begin{equation} \label{eq:NormConstant}
	p(y_t | y_{1:t-1}) = \int_{-\infty}^{\infty} p(y_t | x_t) p(x_t | y_{1:t-1}) \; \mathrm{d} x_{t}
\end{equation}

Computing \eqref{eq:NormConstant} isn't however strictily needed as it does not depend on \(x_t\) and
serves as a normalising constant in \eqref{eq:APosterioriPdf}. Depending on use-case the normalising
constant may not be needed at all or may be computed alternatively using the fact that \(p(x_t | y_{1:y})\)
integrates to \(1\).

We have shown that so called \emph{optimal Bayesian solution} can be easily analytically inferred
using only \emph{chain rule for \pdfs}, \emph{marginalization} and \emph{Bayes' theorem}. (equations
\eqref{eq:APrioriPdf}, \eqref{eq:APosterioriPdf} and \eqref{eq:NormConstant} forming the main steps of the
solution) On the other hand, using this
method directly in practice proves difficult because at least one multidimensional integration has
to be performed (in \eqref{eq:APrioriPdf}), which is (in its general form) hardly tractable for
greater than small state vector dimensions.

This is a motivation for various simplicifations ans approximations among which we have chosen
Kalman filter described in the next section and particle filter family described later.

MAIN SOURCE: \cite{AruMasGor:02} TODO: how to cite?

\section{Kalman Filter}

\section{Particle Filter}

\section{Marginalized Particle Filter}


\chapter{Software analysis}

\section{Requirements}

Ideal library for Bayesian filtering would posses following properties...:

\section{Programming paradigms}

Interpreted vs. Compiled

Object-oriented, procedural and Functional

pass-by reference vs. copy-on-write (Matlab)

\section{Survey of Existing Libraries for Bayesian estimation/decision making}

Brief survey of existing libraries ... not fullfilling all requirements..

The need to implement a new one :-)

\section{C++}

BDM

 - advantages of C (speed, C prevalence (many optimised libraries, BLAS, LAPACK.., OpenMP)

 - disadvantages of C in our ``situation'' (steep learning curve, coplexity because of low-levelness
   high initial barriers (need to have compiler, libraries...), inconveniently long edit/build/test
   process)

\section{Matlab}

BDM (partially?)

 - advantages (popularity, existing toolboxes, rapid development (high-level)

 - disadv: strict copy-on-write, problematic object model (not in original design), difficulties
           interfacing existing C (F) code

\section{Python}

NumPy.... parallelisation (approaches, improvements in Py 3.2) - GIL.. Py3k

\section{Cython}

general info etc... extension types, building, ease of interfacing C (and F) code, .pxd files,
NumPy support

[citations:\cite{BehBraSel:09,Sel:09,BehBraCitDalSelSmi:11}]

\subsection{Gradual Optimisation}

how can optimisaion be approached (gradually) and why this approach is superior

integrate\_python\_cython example (``100x'' speedup for a special (very simple) case)

\subsection{Parallelisation}

integrate\_python\_cython patched with OpenMP (13x speedup in 16-core system)

prange CEP

\subsection{Pure Python mode}

About it and why it should be used in a hypothetical bayesian python library

\subsection{Limitations}

2 types:

	not-supported code (few cases, but bad, ongoing work)

	not-optimised code (much more work needed, but not hard to fix in most cases)

		- exception handling (functions returning void etc)

		- limitations of pure python mode in regards to traditional .pyx files

\section{Choice}

python/cython was choosen ...


\chapter{The PyBayes Library}

Introduction, general directions, future considerations

+ open development on github, open-source

\section{Interpreted and Compiled}

\section{Library Layout}

[proposed citation: \cite{Smi:05}]

\subsection{Random Variable Meta-representation}

Why it is needed (ref to ProdCPdf)

\subsection{Probability Density Functions}

Nice UML diagrams! (better more smaller UMLs than one big) One for general pdf layut, one for
AbstractGaussPdf family, one for AbstractEmpPdf family

\subsection{Bayesian Filters}

UML

Nice graph of a run of a particle filter (Mirda has the plotting code)

similar of marginalized particle filter? (gausses would be plotted vertically)

[mention this:\cite{Smi:10}]

\section{Documentation, Testing and Profiling}

TODO: move above Library Layout?

Documenting using Sphinx, approach to documentation (mathematician-oriented), math in documentation

Testing - the separation of

- tests: test one class in isolation, quick, determinism (would be good, not achievable)

- stresses: test a great portion of code at once, run longer, non-determinism..

Profiling python/cython - how, existing support in PyBayes

- how to correct profiling-induced overhead

\section{Comparison with BDM}


\chapter*{Conclusion} \addcontentsline{toc}{chapter}{Conclusion}


% použitá literatura
\clearpage % so that the contents link mentions correct page
\phantomsection % so that hyperref makes correct reference
\addcontentsline{toc}{chapter}{\bibname}
\bibliographystyle{plain}
\bibliography{bibliography}

\ifrelease
	% přílohy
	\appendix % aby LaTeX cisloval jinak
	\clearpage % so that the contents link mentions correct page
	\phantomsection % so that hyperref makes correct reference
	\addcontentsline{toc}{chapter}{\appendixname}

	\part*{\appendixname}

	\includepdf[pages=-]{../doc/_build/latex/PyBayes.pdf}
\fi

\end{document}
